{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Markov Models Playground\n",
        "\n",
        "Welcome to this interactive notebook on **Discrete-Time Markov Models (DTMCs)**. You’ll explore how these models work by:\n",
        "- Visualizing state transitions\n",
        "- Simulating random walks\n",
        "- Interacting with example systems\n",
        "\n",
        "Let’s get started!\n",
        "---"
      ],
      "metadata": {
        "id": "3uyC6NVEDXTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "ZwvqTkwzDgs9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJnEfmZTDJkt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from random import choices\n",
        "\n",
        "plt.rcParams['figure.facecolor'] = 'white'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Markov Chain Class"
      ],
      "metadata": {
        "id": "K3wYnFcUDj8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MarkovChainEnv:\n",
        "    def __init__(self, transition_matrix, state_names=None):\n",
        "        self.P = np.array(transition_matrix)\n",
        "        self.num_states = self.P.shape[0]\n",
        "        self.states = state_names if state_names else list(range(self.num_states))\n",
        "\n",
        "    def next_state(self, current_state):\n",
        "        # TODO: return the next state given the current state by sampling from the transition matrix\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def plot_transition_graph(self, highlight_state=None, previous_state=None):\n",
        "        G = nx.DiGraph()\n",
        "        for i in range(self.num_states):\n",
        "            for j in range(self.num_states):\n",
        "                if self.P[i, j] > 0:\n",
        "                    G.add_edge(self.states[i], self.states[j], weight=self.P[i, j])\n",
        "\n",
        "        pos = nx.spring_layout(G, seed=42)\n",
        "        edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
        "\n",
        "        node_colors = []\n",
        "        for state in self.states:\n",
        "            if highlight_state is not None and state == self.states[highlight_state]:\n",
        "                node_colors.append('red')\n",
        "            else:\n",
        "                node_colors.append('lightblue')\n",
        "\n",
        "        edge_colors = []\n",
        "        for u, v in G.edges():\n",
        "            if (previous_state is not None and highlight_state is not None and\n",
        "                u == self.states[previous_state] and v == self.states[highlight_state]):\n",
        "                edge_colors.append('red')\n",
        "            else:\n",
        "                edge_colors.append('gray')\n",
        "\n",
        "        nx.draw(G, pos, with_labels=True, node_size=1500, node_color=node_colors, font_size=12, edge_color=edge_colors, width=2)\n",
        "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "        plt.title(\"Markov Chain Transition Graph\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def simulate_walk(self, start_state, steps=10):\n",
        "        current = start_state\n",
        "        walk = [current]\n",
        "        for _ in range(steps):\n",
        "            current = self.next_state(current)\n",
        "            walk.append(current)\n",
        "        return walk\n",
        "\n",
        "\n",
        "    def compute_stationary_distribution(self, tol=1e-8, max_iter=10000):\n",
        "        dist = np.ones(self.num_states) / self.num_states\n",
        "        for _ in range(max_iter):\n",
        "            new_dist = dist @ self.P\n",
        "            if np.allclose(new_dist, dist, atol=tol):\n",
        "                break\n",
        "            dist = new_dist\n",
        "        return dist"
      ],
      "metadata": {
        "id": "eAsphGTVDlpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define A Markov Chain\n",
        "\n",
        "Here, we define a basic 3-state Markov chain to demonstrate how a system transitions between discrete states over time. We'll use this model to simulate a walk and visualize its behavior."
      ],
      "metadata": {
        "id": "_byKb6KuDpAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classic_chain = MarkovChainEnv(\n",
        "    transition_matrix=[\n",
        "        [0.1, 0.1, 0.8],\n",
        "        [0.3, 0.4, 0.3],\n",
        "        [0.5, 0.4, 0.1]\n",
        "    ],\n",
        "    state_names=['A', 'B', 'C']\n",
        ")\n",
        "\n",
        "classic_chain.plot_transition_graph()"
      ],
      "metadata": {
        "id": "yuPSIDeSDqew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulate a Random Walk\n",
        "We now simulate a random walk beginning in state A (`index 0`) and running for 15 steps. This helps us understand how the chain evolves over time using the defined transition probabilities."
      ],
      "metadata": {
        "id": "kVKPzLqSESVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "walk = classic_chain.simulate_walk(start_state=0, steps=15)\n",
        "print(\"Simulated Walk:\", [classic_chain.states[i] for i in walk])"
      ],
      "metadata": {
        "id": "kNqrP52gER5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another Example: Absorbing Markov Chain\n",
        "\n",
        "In this example, we introduce an *absorbing state* — a state that, once entered, cannot be left (e.g., state D). Absorbing Markov chains are useful for modeling systems with terminal outcomes, such as failure, success, or exit conditions."
      ],
      "metadata": {
        "id": "ASAOVHjJEHPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "absorbing_chain = MarkovChainEnv(\n",
        "    transition_matrix=[\n",
        "        [0.5, 0.5, 0.0, 0.0],\n",
        "        [0.2, 0.6, 0.2, 0.0],\n",
        "        [0.0, 0.3, 0.4, 0.3],\n",
        "        [0.0, 0.0, 0.0, 1.0]  # absorbing state D\n",
        "    ],\n",
        "    state_names=['A', 'B', 'C', 'D']\n",
        ")\n",
        "\n",
        "absorbing_chain.plot_transition_graph()"
      ],
      "metadata": {
        "id": "F6ppfJxEEIdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk = absorbing_chain.simulate_walk(start_state=0, steps=15)\n",
        "print(\"Simulated Walk:\", [absorbing_chain.states[i] for i in walk])"
      ],
      "metadata": {
        "id": "0iOv1m7KEZTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interactive Random Walk Simulator\n",
        "\n",
        "Use the interactive widgets below to:\n",
        "- Choose a starting state\n",
        "- Step through the simulation\n",
        "- Visualize transitions and changes in real time\n",
        "\n",
        "This tool helps you build intuition about how a Markov chain behaves step by step."
      ],
      "metadata": {
        "id": "6i70Z-OCEjV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Store simulation state\n",
        "class MarkovStepper:\n",
        "    def __init__(self, chain):\n",
        "        self.chain = chain\n",
        "        self.setup_widgets()  # Setup widgets first\n",
        "        self.reset()\n",
        "\n",
        "    def plot_state_over_time(self, walk, states, title=None):\n",
        "        time_steps = list(range(len(walk)))\n",
        "        unique_states = sorted(set(walk))\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.plot(time_steps, walk, drawstyle='steps-post', marker='o')\n",
        "        plt.title(title or \"State Over Time\")\n",
        "        plt.xlabel(\"Time step\")\n",
        "        plt.ylabel(\"State\")\n",
        "        plt.xticks(time_steps)\n",
        "        plt.yticks(unique_states, [states[s] for s in unique_states])\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def reset(self, start_state=0):\n",
        "        self.current_state = start_state\n",
        "        self.walk = [self.current_state]\n",
        "        self.output.clear_output()\n",
        "        with self.output:\n",
        "            print(f\"Start at: {self.chain.states[self.current_state]}\")\n",
        "            self.chain.plot_transition_graph(highlight_state=self.current_state)\n",
        "            self.plot_state_over_time(self.walk, self.chain.states, title=\"State Over Time (t = 0)\")\n",
        "\n",
        "\n",
        "    def step(self, _=None):\n",
        "        prev_state = self.current_state\n",
        "        next_state = self.chain.next_state(self.current_state)\n",
        "        self.current_state = next_state\n",
        "        self.walk.append(self.current_state)\n",
        "\n",
        "        with self.output:\n",
        "            clear_output(wait=True)\n",
        "            print(f\"Step {len(self.walk)-1}: {self.chain.states[self.current_state]}\")\n",
        "            self.chain.plot_transition_graph(highlight_state=self.current_state, previous_state=prev_state)\n",
        "            self.plot_state_over_time(self.walk, self.chain.states, title=\"State Over Time (t = 0)\")\n",
        "\n",
        "\n",
        "\n",
        "    def display(self):\n",
        "        display(widgets.HBox([self.start_widget, self.reset_button, self.step_button]))\n",
        "        display(self.output)\n",
        "\n",
        "    def setup_widgets(self):\n",
        "        self.start_widget = widgets.Dropdown(\n",
        "            options=[(name, i) for i, name in enumerate(self.chain.states)],\n",
        "            value=0,\n",
        "            description='Start:'\n",
        "        )\n",
        "        self.start_widget.observe(self.on_start_change, names='value')\n",
        "\n",
        "        self.step_button = widgets.Button(description=\"Next Step\")\n",
        "        self.step_button.on_click(self.step)\n",
        "\n",
        "        self.reset_button = widgets.Button(description=\"Reset\")\n",
        "        self.reset_button.on_click(self.on_reset)\n",
        "\n",
        "        self.output = widgets.Output()\n",
        "\n",
        "    def on_reset(self, _=None):\n",
        "        self.reset(self.start_widget.value)\n",
        "\n",
        "    def on_start_change(self, change):\n",
        "        self.reset(change['new'])\n"
      ],
      "metadata": {
        "id": "Urr7nFTXEimc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classic_stepper = MarkovStepper(classic_chain)\n",
        "classic_stepper.setup_widgets()\n",
        "classic_stepper.display()\n",
        "classic_stepper.reset()\n"
      ],
      "metadata": {
        "id": "SkiBzD4sEqTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two Spies\n",
        "\n",
        "Let's create the Markov chain that describes the Deep Cover Spy's transitions."
      ],
      "metadata": {
        "id": "Fy0MoPg3o1EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deep_cover_chain = None\n",
        "\n",
        "deep_cover_stepper = MarkovStepper(deep_cover_chain)\n",
        "deep_cover_stepper.setup_widgets()\n",
        "deep_cover_stepper.display()\n",
        "deep_cover_stepper.reset()\n"
      ],
      "metadata": {
        "id": "Lv707TcHo8bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hidden Markov Models\n",
        "\n",
        "Here, we introduce Hidden Markov Models. Unlike standard Markov chains, HMMs include:\n",
        "- A transition matrix for hidden states\n",
        "- An sensor matrix that links hidden states to observable outputs\n",
        "\n",
        "This lets us model systems where we can only indirectly observe the true state."
      ],
      "metadata": {
        "id": "jbqGZ2CIpG_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "class HiddenMarkovModelEnv:\n",
        "    def __init__(self, transition_matrix, sensor_matrix, initial_probs, state_names=None, observation_names=None):\n",
        "        self.transition_matrix = np.array(transition_matrix)\n",
        "        self.sensor_matrix = np.array(sensor_matrix)\n",
        "        self.pi = np.array(initial_probs)\n",
        "\n",
        "        self.num_states = self.transition_matrix.shape[0]\n",
        "        self.num_obs = self.sensor_matrix.shape[1]\n",
        "\n",
        "        self.states = state_names if state_names else list(range(self.num_states))\n",
        "        self.observations = observation_names if observation_names else list(range(self.num_obs))\n",
        "\n",
        "    def next_state(self, current_state):\n",
        "        return np.random.choice(self.num_states, p=self.transition_matrix[current_state])\n",
        "\n",
        "    def emit(self, state):\n",
        "        return np.random.choice(self.num_obs, p=self.sensor_matrix[state])\n",
        "\n",
        "    def simulate_walk(self, steps=10, start_state=None):\n",
        "        if start_state is None:\n",
        "            current = np.random.choice(self.num_states, p=self.pi)\n",
        "        else:\n",
        "            current = start_state\n",
        "\n",
        "        hidden = [current]\n",
        "        observed = [self.emit(current)]\n",
        "\n",
        "        for _ in range(steps):\n",
        "            current = self.next_state(current)\n",
        "            hidden.append(current)\n",
        "            observed.append(self.emit(current))\n",
        "\n",
        "        return [self.states[s] for s in hidden], [self.observations[o] for o in observed]\n",
        "\n",
        "    def plot_observations(self, observed_seq, title=\"Observations Over Time\"):\n",
        "        time_steps = list(range(len(observed_seq)))\n",
        "        obs_indices = [self.observations.index(o) if o in self.observations else o for o in observed_seq]\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(time_steps, obs_indices, drawstyle='steps-post', marker='o')\n",
        "        plt.title(title)\n",
        "        plt.xlabel(\"Time Step\")\n",
        "        plt.ylabel(\"Observation\")\n",
        "        plt.yticks(range(self.num_obs), self.observations)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_transition_graph(self):\n",
        "        G = nx.DiGraph()\n",
        "        for i in range(self.num_states):\n",
        "            for j in range(self.num_states):\n",
        "                if self.transition_matrix[i, j] > 0:\n",
        "                    G.add_edge(self.states[i], self.states[j], weight=self.transition_matrix[i, j])\n",
        "\n",
        "        pos = nx.spring_layout(G, seed=42)\n",
        "        edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
        "\n",
        "        nx.draw(G, pos, with_labels=True, node_size=1500, node_color=\"lightblue\", font_size=12, edge_color=\"gray\", width=2)\n",
        "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "        plt.title(\"HMM Transition Graph\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "1UkBrwfiGBKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a MarkovChain instance for hidden state transitions\n",
        "\n",
        "weather_hmm = HiddenMarkovModelEnv(\n",
        "    transition_matrix=[\n",
        "        [0.7, 0.3],  # Rainy → Rainy, Sunny\n",
        "        [0.4, 0.6]   # Sunny → Rainy, Sunny\n",
        "    ],\n",
        "    sensor_matrix=[\n",
        "        [0.1, 0.4, 0.5],  # Rainy → Walk, Shop, Clean\n",
        "        [0.6, 0.3, 0.1]   # Sunny → Walk, Shop, Clean\n",
        "    ],\n",
        "    initial_probs=[0.6, 0.4],\n",
        "    state_names=[\"Rainy\", \"Sunny\"],\n",
        "    observation_names=[\"Walk\", \"Shop\", \"Clean\"]\n",
        ")\n",
        "\n",
        "weather_hmm.plot_transition_graph()\n"
      ],
      "metadata": {
        "id": "WzjxNcepUvjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden, observed = weather_hmm.simulate_walk(steps=10)\n",
        "\n",
        "print(\"Hidden states: \", hidden)\n",
        "print(\"Observed output:\", observed)\n",
        "weather_hmm.plot_observations(observed)\n"
      ],
      "metadata": {
        "id": "6kmngtFUi28A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two Spies\n",
        "\n",
        "Now we define the complete Hidden Markov Model for our Two Spies scenario, incorporating both:\n",
        "- Hidden transitions (spy movement)\n",
        "- Noisy observations (sensor readings)"
      ],
      "metadata": {
        "id": "kQxR4dIOpS8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: implement the Two Spies Deep Cover HMM"
      ],
      "metadata": {
        "id": "b0eEQ_zOkizW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}